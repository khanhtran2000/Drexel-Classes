{"cells":[{"metadata":{},"cell_type":"markdown","source":"### College of Computing and Informatics, Drexel University\n### INFO 213: Data Science Programming II\n---\n\n## Project Proposal\n\n## Project Title: Countrywide Car Accidents Analysis and Forecasting\n\n## Student(s): Khanh Tran, Mark Amon, Amanjyot Singh\n\n#### Date: August 10, 2020\n---"},{"metadata":{},"cell_type":"markdown","source":"#### Purpose\n---\nYou are asked to propose a final project and present in the class. This proposal should describe the problem, the data sets, and the goal(s) of the project. Use the Project Requirements at the end of this notebook for choosing and scoping your project. "},{"metadata":{},"cell_type":"markdown","source":"### 1. Introduction\n---\n*(Introduce the project and describe the objectives.)* "},{"metadata":{},"cell_type":"markdown","source":"With a good amount of data and thoroughly executed analytics, one can possibly unveil the many faces of a problem or phenomenon. Data science has been being considered the most direct and reliable way to attack a problem, tracing it to the root and predicting what and when next consequences will take place. This project will follow the same direction and try to solve a specific real-world problem: what can data analytics do to reduce the number of car accidents in the U.S. The analytics will be based on “A Countrywide Traffic Accident Dataset” by Moosavi, Sobhan, Mohammad Hossein Samavatian, Srinivasan Parthasarathy, and Rajiv Ramnath. In this project, we will strive for understanding the cause and effect rules of the accidents, and from that, we will try to build several machine learning models that can help with the future accidents forecasting."},{"metadata":{},"cell_type":"markdown","source":"### 2. Problem Definition\n---\n*(Define the problem that will be solved in this data analytics project.)*"},{"metadata":{},"cell_type":"markdown","source":"On average, there are 6 million car accidents in the U.S. every year. That's roughly 16,438 per day. Over 37,000 Americans die in automobile crashes per year, and there is an additional 3 million injured or disabled annually. Economically, traffic accidents cost the country $871 billion a year, and that was 6 years ago. These are only a few quick car crash statistics happening right now in the U.S. Even though the country is standing at 110th on the list of countries with the highest traffic-related death rate, the number can still be lowered tremendously if science-based solutions are carried out in a mission to improve the safety of the people on the roads. With a good dataset, data analysis can be an efficient method to extract useful information in order to figure out the cause and effect rules of the accidents, which will result in improved accident prevention."},{"metadata":{},"cell_type":"markdown","source":"### 3. Data Sources\n---\n*(Describe the origin of the data sources. What is the format of the original data? How to access the data?)*"},{"metadata":{},"cell_type":"markdown","source":"As the dataset was acquired on Kaggle and because of its size, downloading it to local computers will be quite time-consuming. Using Kaggle notebook will solve this problem as we don't have to manually download the dataset to use it. Kaggle allows their users to get access to the datasets available on their website. There are currently about 3.5 million accident records in this dataset. It covers 49 states of the USA, and the data were collected from February 2016 to June 2020, using two APIs that provide streaming traffic incident (or event) data. Along with the large number of records, this dataset also provide a wide range of attributes for each accident. With 49 columns, analysts can observe and discover many faces of the accidents such as starting-ending time, exact starting-ending location, address, weather conditions, existed crossings, junctions, or bumps, etc. Our goals are planned upon this variety of features. We will also make use of pandas, numpy, matplotlib.pyplot, math, and sklearn packages of Python to effectively analyze, visualize, and model our data.\n\nAcknowledgements\n\n- Moosavi, Sobhan, Mohammad Hossein Samavatian, Srinivasan Parthasarathy, and Rajiv Ramnath. “A Countrywide Traffic Accident Dataset.”, 2019.\n\n- Moosavi, Sobhan, Mohammad Hossein Samavatian, Srinivasan Parthasarathy, Radu Teodorescu, and Rajiv Ramnath. \"Accident Risk Prediction based on Heterogeneous Sparse Data: New Dataset and Insights.\" In proceedings of the 27th ACM SIGSPATIAL International Conference on Advances in Geographic Information Systems, ACM, 2019.\n\nhttps://www.kaggle.com/sobhanmoosavi/us-accidents"},{"metadata":{},"cell_type":"markdown","source":"### 4. The Goal(s) of the predictions\n---\n*(What are the expected results of the project?)*"},{"metadata":{},"cell_type":"markdown","source":"The project's mission is to provide assitance for this battle against car accidents with statistics-based findings and data-based analysis. To be more specific, we strive for determining the importance of each attribute toward predicting severity levels of accidents. The process is to create two similar models that predict severity level of available accidents based on a set of attributes. One model will take in all attributes except for the target attribute, for example weather conditions, and the other one will take in every attribute including the target attribute. Two sets of metric scores will be calculated and compared to see if adding the target attribute to the model will improve its performance or hurt it. Additionally, the level of influence of each target attribute will also be evaluated to find out which one plays the most important role and which one plays the least in supporting the performance of the algorithms. The target attributes are:\n\n- Weather Conditions\n- Locations\n- Time of the day\n- Time of the year\n\nFor each attribute, we will create a separate set of models. We will try to implement as many machine learning algorithms as possible. Each of the attribute listed above will be carefully processed and feeded into the models, making sure they retain their full features and hopefully are influential enough to affect the performance of the algorithms for the better or worse. "},{"metadata":{},"cell_type":"markdown","source":"### 5. Preliminary Models\n---"},{"metadata":{},"cell_type":"markdown","source":"In this section, we will examine the possibility of achieving the goals mentioned above. We will use 8 different models which are listed below in the code. The goal is to make sure the models work fluently without errors, quickly examine the performance of the models, and find out if the target attribute in this example improves or hurts the accuracy. Weather conditions will be the target attribute for these preliminary models."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Import models \nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.metrics import r2_score, mean_squared_error\nimport matplotlib.pyplot as plt\nimport pandas as  pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import Perceptron\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import train_test_split\n\ndf = pd.read_csv(\"../input/us-accidents/US_Accidents_June20.csv\")\ndf.head()","execution_count":2,"outputs":[{"output_type":"execute_result","execution_count":2,"data":{"text/plain":"    ID    Source    TMC  Severity           Start_Time             End_Time  \\\n0  A-1  MapQuest  201.0         3  2016-02-08 05:46:00  2016-02-08 11:00:00   \n1  A-2  MapQuest  201.0         2  2016-02-08 06:07:59  2016-02-08 06:37:59   \n2  A-3  MapQuest  201.0         2  2016-02-08 06:49:27  2016-02-08 07:19:27   \n3  A-4  MapQuest  201.0         3  2016-02-08 07:23:34  2016-02-08 07:53:34   \n4  A-5  MapQuest  201.0         2  2016-02-08 07:39:07  2016-02-08 08:09:07   \n\n   Start_Lat  Start_Lng  End_Lat  End_Lng  ...  Roundabout Station   Stop  \\\n0  39.865147 -84.058723      NaN      NaN  ...       False   False  False   \n1  39.928059 -82.831184      NaN      NaN  ...       False   False  False   \n2  39.063148 -84.032608      NaN      NaN  ...       False   False  False   \n3  39.747753 -84.205582      NaN      NaN  ...       False   False  False   \n4  39.627781 -84.188354      NaN      NaN  ...       False   False  False   \n\n  Traffic_Calming Traffic_Signal Turning_Loop Sunrise_Sunset Civil_Twilight  \\\n0           False          False        False          Night          Night   \n1           False          False        False          Night          Night   \n2           False           True        False          Night          Night   \n3           False          False        False          Night            Day   \n4           False           True        False            Day            Day   \n\n  Nautical_Twilight Astronomical_Twilight  \n0             Night                 Night  \n1             Night                   Day  \n2               Day                   Day  \n3               Day                   Day  \n4               Day                   Day  \n\n[5 rows x 49 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>Source</th>\n      <th>TMC</th>\n      <th>Severity</th>\n      <th>Start_Time</th>\n      <th>End_Time</th>\n      <th>Start_Lat</th>\n      <th>Start_Lng</th>\n      <th>End_Lat</th>\n      <th>End_Lng</th>\n      <th>...</th>\n      <th>Roundabout</th>\n      <th>Station</th>\n      <th>Stop</th>\n      <th>Traffic_Calming</th>\n      <th>Traffic_Signal</th>\n      <th>Turning_Loop</th>\n      <th>Sunrise_Sunset</th>\n      <th>Civil_Twilight</th>\n      <th>Nautical_Twilight</th>\n      <th>Astronomical_Twilight</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>A-1</td>\n      <td>MapQuest</td>\n      <td>201.0</td>\n      <td>3</td>\n      <td>2016-02-08 05:46:00</td>\n      <td>2016-02-08 11:00:00</td>\n      <td>39.865147</td>\n      <td>-84.058723</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>Night</td>\n      <td>Night</td>\n      <td>Night</td>\n      <td>Night</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>A-2</td>\n      <td>MapQuest</td>\n      <td>201.0</td>\n      <td>2</td>\n      <td>2016-02-08 06:07:59</td>\n      <td>2016-02-08 06:37:59</td>\n      <td>39.928059</td>\n      <td>-82.831184</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>Night</td>\n      <td>Night</td>\n      <td>Night</td>\n      <td>Day</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>A-3</td>\n      <td>MapQuest</td>\n      <td>201.0</td>\n      <td>2</td>\n      <td>2016-02-08 06:49:27</td>\n      <td>2016-02-08 07:19:27</td>\n      <td>39.063148</td>\n      <td>-84.032608</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>Night</td>\n      <td>Night</td>\n      <td>Day</td>\n      <td>Day</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>A-4</td>\n      <td>MapQuest</td>\n      <td>201.0</td>\n      <td>3</td>\n      <td>2016-02-08 07:23:34</td>\n      <td>2016-02-08 07:53:34</td>\n      <td>39.747753</td>\n      <td>-84.205582</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>Night</td>\n      <td>Day</td>\n      <td>Day</td>\n      <td>Day</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>A-5</td>\n      <td>MapQuest</td>\n      <td>201.0</td>\n      <td>2</td>\n      <td>2016-02-08 07:39:07</td>\n      <td>2016-02-08 08:09:07</td>\n      <td>39.627781</td>\n      <td>-84.188354</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>Day</td>\n      <td>Day</td>\n      <td>Day</td>\n      <td>Day</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 49 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"For proposal purposes, we have decided to keep 30k records to decrease the running times. This will be changed in our final report. Furthermore, we will use more attributes in our final report. These are used just for proposal purposes. "},{"metadata":{"trusted":true},"cell_type":"code","source":"# With the Weather_Condition column\ndf2 = df[[\"Distance(mi)\", \n          \"Temperature(F)\", \n          \"Wind_Chill(F)\", \n          \"Humidity(%)\", \n          \"Pressure(in)\", \n          \"Visibility(mi)\", \n          \"Precipitation(in)\", \n          \"Weather_Condition\",\n         \"Severity\"]]\n\n# Without the Weather_Condition column\ndf1 = df[[\"Distance(mi)\",  \n          \"Temperature(F)\", \n          \"Wind_Chill(F)\", \n          \"Humidity(%)\", \n          \"Pressure(in)\", \n          \"Visibility(mi)\", \n          \"Precipitation(in)\",\n          \"Severity\"\n          ]]\n\ndf1.replace(-1, np.nan, inplace=True)  \ndf1 = df1.dropna()\n\ndf2.replace(-1, np.nan, inplace=True)  \ndf2 = df2.dropna()\n\n# Keep 30000 to decrease running times\ndf1 = df1[:30000] \ndf2 = df2[:30000] \n\n\nY1 = df1.Severity.values\nX1 = df1.loc[:, df1.columns != 'Severity']","execution_count":3,"outputs":[{"output_type":"stream","text":"/opt/conda/lib/python3.7/site-packages/pandas/core/frame.py:4379: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  method=method,\n/opt/conda/lib/python3.7/site-packages/pandas/core/frame.py:4379: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  method=method,\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(Y1.shape)\nprint(X1.shape)","execution_count":16,"outputs":[{"output_type":"stream","text":"(30000,)\n(30000, 7)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"X1.head()","execution_count":6,"outputs":[{"output_type":"execute_result","execution_count":6,"data":{"text/plain":"    Distance(mi)  Temperature(F)  Wind_Chill(F)  Humidity(%)  Pressure(in)  \\\n5           0.01            37.9           35.5         97.0         29.63   \n9           0.01            37.4           33.8        100.0         29.62   \n11          0.01            37.4           33.8        100.0         29.62   \n14          0.01            37.4           33.8        100.0         29.62   \n20          0.00            33.8           29.6        100.0         29.62   \n\n    Visibility(mi)  Precipitation(in)  \n5              7.0               0.03  \n9              3.0               0.02  \n11             3.0               0.02  \n14             3.0               0.02  \n20             2.0               0.01  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Distance(mi)</th>\n      <th>Temperature(F)</th>\n      <th>Wind_Chill(F)</th>\n      <th>Humidity(%)</th>\n      <th>Pressure(in)</th>\n      <th>Visibility(mi)</th>\n      <th>Precipitation(in)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>5</th>\n      <td>0.01</td>\n      <td>37.9</td>\n      <td>35.5</td>\n      <td>97.0</td>\n      <td>29.63</td>\n      <td>7.0</td>\n      <td>0.03</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0.01</td>\n      <td>37.4</td>\n      <td>33.8</td>\n      <td>100.0</td>\n      <td>29.62</td>\n      <td>3.0</td>\n      <td>0.02</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>0.01</td>\n      <td>37.4</td>\n      <td>33.8</td>\n      <td>100.0</td>\n      <td>29.62</td>\n      <td>3.0</td>\n      <td>0.02</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>0.01</td>\n      <td>37.4</td>\n      <td>33.8</td>\n      <td>100.0</td>\n      <td>29.62</td>\n      <td>3.0</td>\n      <td>0.02</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>0.00</td>\n      <td>33.8</td>\n      <td>29.6</td>\n      <td>100.0</td>\n      <td>29.62</td>\n      <td>2.0</td>\n      <td>0.01</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train1, X_test1,Y_train1,Y_test1 = train_test_split(X1, Y1, test_size=0.33, random_state=99)\n#Without weather\n\nsvc = SVC()\nsvc.fit(X_train1, Y_train1)\nY_pred = svc.predict(X_test1)\nacc_svc1 = round(svc.score(X_test1, Y_test1) * 100, 2)\nprint(\"Accuracy SVC: \" , acc_svc1)\n\nknn = KNeighborsClassifier(n_neighbors = 3)\nknn.fit(X_train1, Y_train1)\nY_pred = knn.predict(X_test1)\nacc_knn1 = round(knn.score(X_test1, Y_test1) * 100, 2)\nprint(\"Accuracy KNN: \" , acc_knn1)\n\n\n# Logistic Regression\nlogreg = LogisticRegression(max_iter = 2000)\nlogreg.fit(X_train1, Y_train1)\nY_pred = logreg.predict(X_test1)\nacc_log1 = round(logreg.score(X_train1, Y_train1) * 100, 2)\nprint(\"Accuracy Log: \", acc_log1)\n\n\n# Gaussian Naive Bayes\n\ngaussian = GaussianNB()\ngaussian.fit(X_train1, Y_train1)\nY_pred = gaussian.predict(X_test1)\nacc_gaussian1 = round(gaussian.score(X_test1, Y_test1) * 100, 2)\nprint(\"Accuracy Gaussian: \", acc_gaussian1)\n\n# Perceptron\n\nperceptron = Perceptron()\nperceptron.fit(X_train1, Y_train1)\nY_pred = perceptron.predict(X_test1)\nacc_perceptron1 = round(perceptron.score(X_test1, Y_test1) * 100, 2)\nprint(\"Accuracy Perceptron: \", acc_perceptron1)\n\n# Linear SVC\n\n#linear_svc = LinearSVC(max_iter = 10000)\n#linear_svc.fit(X_train1, Y_train1)\n#Y_pred = linear_svc.predict(X_test1)\n#acc_linear_svc1 = round(linear_svc.score(X_test1, Y_test1) * 100, 2)\n#print(\"Accuracy Linear SVC: \", acc_linear_svc1)\n\n# Stochastic Gradient Descent\n\nsgd = SGDClassifier()\nsgd.fit(X_train1, Y_train1)\nY_pred = sgd.predict(X_test1)\nacc_sgd1 = round(sgd.score(X_test1, Y_test1) * 100, 2)\nprint(\"Accuracy SGD: \", acc_sgd1)\n\n# Decision Tree\n\ndecision_tree = DecisionTreeClassifier()\ndecision_tree.fit(X_train1, Y_train1)\nY_pred = decision_tree.predict(X_test1)\nacc_decision_tree1 = round(decision_tree.score(X_test1, Y_test1) * 100, 2)\nprint(\"Accuracy Decision Tree: \", acc_decision_tree1)\n\n# Random Forest\n\nrandom_forest = RandomForestClassifier(n_estimators=100)\nrandom_forest.fit(X_train1, Y_train1)\nY_pred = random_forest.predict(X_test1)\nrandom_forest.score(X_train1, Y_train1)\nacc_random_forest1 = round(random_forest.score(X_test1, Y_test1) * 100, 2)\nprint(\"Accuracy Random Forest: \", acc_random_forest1)","execution_count":7,"outputs":[{"output_type":"stream","text":"Accuracy SVC:  66.34\nAccuracy KNN:  63.0\nAccuracy Log:  67.77\nAccuracy Gaussian:  25.65\nAccuracy Perceptron:  40.52\nAccuracy SGD:  57.87\nAccuracy Decision Tree:  64.1\nAccuracy Random Forest:  68.62\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"When feeding weather conditions to the models, we have to use a technique call one-hot encoding since this is a categorical variable. In other words, we will map the values of this attribute to numerical values."},{"metadata":{"trusted":true},"cell_type":"code","source":"df2[\"Weather_Condition\"].unique()","execution_count":13,"outputs":[{"output_type":"execute_result","execution_count":13,"data":{"text/plain":"array(['Light Rain', 'Light Snow', 'Overcast', 'Mostly Cloudy', 'Snow',\n       'Light Freezing Drizzle', 'Rain', 'Heavy Rain',\n       'Light Freezing Rain', 'Cloudy', 'Clear', 'Light Freezing Fog',\n       'Scattered Clouds', 'Haze', 'Partly Cloudy', 'Fair', 'Fog',\n       'Smoke', 'Blowing Dust / Windy', 'Fair / Windy',\n       'Light Rain / Windy', 'Light Thunderstorms and Rain',\n       'Showers in the Vicinity', 'Light Rain Shower',\n       'Light Rain with Thunder', 'Mostly Cloudy / Windy',\n       'Partly Cloudy / Windy', 'Light Drizzle',\n       'Thunder in the Vicinity', 'T-Storm', 'Thunder', 'Heavy T-Storm',\n       'Heavy T-Storm / Windy', 'Blowing Snow', 'Drizzle',\n       'Thunderstorms and Rain', 'Light Thunderstorms and Snow',\n       'Heavy Thunderstorms and Rain', 'Heavy Snow', 'Light Ice Pellets',\n       'Light Rain Showers', 'Mist', 'Ice Pellets', 'Heavy Drizzle',\n       'N/A Precipitation', 'Cloudy / Windy',\n       'Heavy Thunderstorms and Snow', 'Rain / Windy',\n       'Heavy Rain / Windy', 'Heavy Ice Pellets', 'Light Snow / Windy',\n       'Heavy Freezing Rain', 'Small Hail', 'Thunderstorm',\n       'Patches of Fog', 'T-Storm / Windy', 'Patches of Fog / Windy',\n       'Drizzle / Windy', 'Thunder / Windy'], dtype=object)"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"As there are a variety of different values indicating different weather conditions, for the sake of the main goal of this example, we will simplify it to \"Rain\", \"Snow, \"Fog\", and \"Other\". \"Rain\" will be mapped to 1, \"Snow\" is 2, \"Fog\" is 3, and \"Other\" is 4."},{"metadata":{"trusted":true},"cell_type":"code","source":"# One-hot encoding\nencoded_cons = []\nfor con in df2[\"Weather_Condition\"].values:\n    if \"Rain\" in con.split(\" \"):\n        encoded_cons.append(1)\n    elif \"Snow\" in con.split(\" \"):\n        encoded_cons.append(2)\n    elif \"Fog\" in con.split(\" \"):\n        encoded_cons.append(3)\n    else:\n        encoded_cons.append(4)\n\n# New column and delete the original Weather_Condition column\ndf2['Encoded_Weather'] = encoded_cons\ndel df2[\"Weather_Condition\"]\n\ndf2","execution_count":15,"outputs":[{"output_type":"execute_result","execution_count":15,"data":{"text/plain":"        Distance(mi)  Temperature(F)  Wind_Chill(F)  Humidity(%)  \\\n5               0.01            37.9           35.5         97.0   \n9               0.01            37.4           33.8        100.0   \n11              0.01            37.4           33.8        100.0   \n14              0.01            37.4           33.8        100.0   \n20              0.00            33.8           29.6        100.0   \n...              ...             ...            ...          ...   \n527539          0.00            64.0           64.0         32.0   \n527540          0.00            59.0           59.0         36.0   \n527541          0.00            63.0           63.0         54.0   \n527542          0.00            59.0           59.0         60.0   \n527543          0.00            68.0           68.0         40.0   \n\n        Pressure(in)  Visibility(mi)  Precipitation(in)  Severity  \\\n5              29.63             7.0               0.03         3   \n9              29.62             3.0               0.02         3   \n11             29.62             3.0               0.02         3   \n14             29.62             3.0               0.02         2   \n20             29.62             2.0               0.01         2   \n...              ...             ...                ...       ...   \n527539         27.44            10.0               0.00         2   \n527540         30.10            10.0               0.00         2   \n527541         30.07            10.0               0.00         2   \n527542         30.05            10.0               0.00         2   \n527543         30.08            10.0               0.00         2   \n\n        Encoded_Weather  \n5                     1  \n9                     1  \n11                    1  \n14                    1  \n20                    2  \n...                 ...  \n527539                4  \n527540                4  \n527541                4  \n527542                4  \n527543                4  \n\n[30000 rows x 9 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Distance(mi)</th>\n      <th>Temperature(F)</th>\n      <th>Wind_Chill(F)</th>\n      <th>Humidity(%)</th>\n      <th>Pressure(in)</th>\n      <th>Visibility(mi)</th>\n      <th>Precipitation(in)</th>\n      <th>Severity</th>\n      <th>Encoded_Weather</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>5</th>\n      <td>0.01</td>\n      <td>37.9</td>\n      <td>35.5</td>\n      <td>97.0</td>\n      <td>29.63</td>\n      <td>7.0</td>\n      <td>0.03</td>\n      <td>3</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0.01</td>\n      <td>37.4</td>\n      <td>33.8</td>\n      <td>100.0</td>\n      <td>29.62</td>\n      <td>3.0</td>\n      <td>0.02</td>\n      <td>3</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>0.01</td>\n      <td>37.4</td>\n      <td>33.8</td>\n      <td>100.0</td>\n      <td>29.62</td>\n      <td>3.0</td>\n      <td>0.02</td>\n      <td>3</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>0.01</td>\n      <td>37.4</td>\n      <td>33.8</td>\n      <td>100.0</td>\n      <td>29.62</td>\n      <td>3.0</td>\n      <td>0.02</td>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>0.00</td>\n      <td>33.8</td>\n      <td>29.6</td>\n      <td>100.0</td>\n      <td>29.62</td>\n      <td>2.0</td>\n      <td>0.01</td>\n      <td>2</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>527539</th>\n      <td>0.00</td>\n      <td>64.0</td>\n      <td>64.0</td>\n      <td>32.0</td>\n      <td>27.44</td>\n      <td>10.0</td>\n      <td>0.00</td>\n      <td>2</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>527540</th>\n      <td>0.00</td>\n      <td>59.0</td>\n      <td>59.0</td>\n      <td>36.0</td>\n      <td>30.10</td>\n      <td>10.0</td>\n      <td>0.00</td>\n      <td>2</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>527541</th>\n      <td>0.00</td>\n      <td>63.0</td>\n      <td>63.0</td>\n      <td>54.0</td>\n      <td>30.07</td>\n      <td>10.0</td>\n      <td>0.00</td>\n      <td>2</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>527542</th>\n      <td>0.00</td>\n      <td>59.0</td>\n      <td>59.0</td>\n      <td>60.0</td>\n      <td>30.05</td>\n      <td>10.0</td>\n      <td>0.00</td>\n      <td>2</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>527543</th>\n      <td>0.00</td>\n      <td>68.0</td>\n      <td>68.0</td>\n      <td>40.0</td>\n      <td>30.08</td>\n      <td>10.0</td>\n      <td>0.00</td>\n      <td>2</td>\n      <td>4</td>\n    </tr>\n  </tbody>\n</table>\n<p>30000 rows × 9 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"Y = df2.Severity.values\nX = df2.loc[:, df2.columns != 'Severity']","execution_count":17,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.head()","execution_count":19,"outputs":[{"output_type":"execute_result","execution_count":19,"data":{"text/plain":"    Distance(mi)  Temperature(F)  Wind_Chill(F)  Humidity(%)  Pressure(in)  \\\n5           0.01            37.9           35.5         97.0         29.63   \n9           0.01            37.4           33.8        100.0         29.62   \n11          0.01            37.4           33.8        100.0         29.62   \n14          0.01            37.4           33.8        100.0         29.62   \n20          0.00            33.8           29.6        100.0         29.62   \n\n    Visibility(mi)  Precipitation(in)  Encoded_Weather  \n5              7.0               0.03                1  \n9              3.0               0.02                1  \n11             3.0               0.02                1  \n14             3.0               0.02                1  \n20             2.0               0.01                2  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Distance(mi)</th>\n      <th>Temperature(F)</th>\n      <th>Wind_Chill(F)</th>\n      <th>Humidity(%)</th>\n      <th>Pressure(in)</th>\n      <th>Visibility(mi)</th>\n      <th>Precipitation(in)</th>\n      <th>Encoded_Weather</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>5</th>\n      <td>0.01</td>\n      <td>37.9</td>\n      <td>35.5</td>\n      <td>97.0</td>\n      <td>29.63</td>\n      <td>7.0</td>\n      <td>0.03</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0.01</td>\n      <td>37.4</td>\n      <td>33.8</td>\n      <td>100.0</td>\n      <td>29.62</td>\n      <td>3.0</td>\n      <td>0.02</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>0.01</td>\n      <td>37.4</td>\n      <td>33.8</td>\n      <td>100.0</td>\n      <td>29.62</td>\n      <td>3.0</td>\n      <td>0.02</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>0.01</td>\n      <td>37.4</td>\n      <td>33.8</td>\n      <td>100.0</td>\n      <td>29.62</td>\n      <td>3.0</td>\n      <td>0.02</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>0.00</td>\n      <td>33.8</td>\n      <td>29.6</td>\n      <td>100.0</td>\n      <td>29.62</td>\n      <td>2.0</td>\n      <td>0.01</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(Y.shape)\nprint(X.shape)","execution_count":20,"outputs":[{"output_type":"stream","text":"(30000,)\n(30000, 8)\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"Pay attention that these new models that are trained on weather conditions will be tested with X_test1 and Y_test1 in order to produce an unbiased accuracy score. "},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train2, X_test2, Y_train2, Y_test2 = train_test_split(X, Y, test_size=0.33, random_state=99)\n#With weather\n\nsvc = SVC()\nsvc.fit(X_train2, Y_train2)\nY_pred = svc.predict(X_test1)\nacc_svc2 = round(svc.score(X_test1, Y_test1) * 100, 2)\nprint(\"Accuracy SVC: \" , acc_svc2)\nprint(\"Improvement: \", acc_svc2 > acc_svc1)\n\n\nknn = KNeighborsClassifier(n_neighbors = 3)\nknn.fit(X_train2, Y_train2)\nY_pred = knn.predict(X_test1)\nacc_knn2 = round(knn.score(X_test1, Y_test1) * 100, 2)\nprint(\"Accuracy KNN: \" , acc_knn2)\nprint(\"Improvement: \", acc_knn2 > acc_knn1)\n\n\n# Logistic Regression\nlogreg = LogisticRegression(max_iter = 2000)\nlogreg.fit(X_train2, Y_train2)\nY_pred = logreg.predict(X_test1)\nacc_log2 = round(logreg.score(X_train1, Y_train1) * 100, 2)\nprint(\"Accuracy Log: \", acc_log2)\nprint(\"Improvement: \", acc_log2 > acc_log1)\n\n\n# Gaussian Naive Bayes\n\ngaussian = GaussianNB()\ngaussian.fit(X_train2, Y_train2)\nY_pred = gaussian.predict(X_test1)\nacc_gaussian2 = round(gaussian.score(X_test1, Y_test1) * 100, 2)\nprint(\"Accuracy Gaussian: \", acc_gaussian2)\nprint(\"Improvement: \", acc_gaussian2 > acc_gaussian1)\n\n# Perceptron\n\nperceptron = Perceptron()\nperceptron.fit(X_train2, Y_train2)\nY_pred = perceptron.predict(X_test1)\nacc_perceptron2 = round(perceptron.score(X_test1, Y_test1) * 100, 2)\nprint(\"Accuracy Perceptron: \", acc_perceptron2)\nprint(\"Improvement: \", acc_perceptron2 > acc_perceptron1)\n\n# Linear SVC\n\n#linear_svc = LinearSVC(max_iter = 10000)\n#linear_svc.fit(X_train1, Y_train1)\n#Y_pred = linear_svc.predict(X_test1)\n#acc_linear_svc1 = round(linear_svc.score(X_test1, Y_test1) * 100, 2)\n#print(\"Accuracy Linear SVC: \", acc_linear_svc1)\n\n# Stochastic Gradient Descent\n\nsgd = SGDClassifier()\nsgd.fit(X_train2, Y_train2)\nY_pred = sgd.predict(X_test1)\nacc_sgd2 = round(sgd.score(X_test1, Y_test1) * 100, 2)\nprint(\"Accuracy SGD: \", acc_sgd2)\nprint(\"Improvement: \", acc_sgd2 > acc_sgd1)\n\n\n# Decision Tree\n\ndecision_tree = DecisionTreeClassifier()\ndecision_tree.fit(X_train2, Y_train2)\nY_pred = decision_tree.predict(X_test1)\nacc_decision_tree2 = round(decision_tree.score(X_test1, Y_test1) * 100, 2)\nprint(\"Accuracy Decision Tree: \", acc_decision_tree2)\nprint(\"Improvement: \", acc_decision_tree2 > acc_decision_tree1)\n\n\n# Random Forest\n\nrandom_forest = RandomForestClassifier(n_estimators=100)\nrandom_forest.fit(X_train2, Y_train2)\nY_pred = random_forest.predict(X_test1)\nrandom_forest.score(X_train1, Y_train1)\nacc_random_forest2 = round(random_forest.score(X_test1, Y_test1) * 100, 2)\nprint(\"Accuracy Random Forest: \", acc_random_forest2)\nprint(\"Improvement: \", acc_random_forest2 > acc_random_forest1)","execution_count":24,"outputs":[{"output_type":"stream","text":"Accuracy SVC:  66.22\nImprovement:  False\nAccuracy KNN:  63.6\nImprovement:  False\nAccuracy Log:  67.71\nImprovement:  False\nAccuracy Gaussian:  43.08\nImprovement:  False\nAccuracy Perceptron:  66.22\nImprovement:  False\nAccuracy SGD:  66.05\nImprovement:  True\nAccuracy Decision Tree:  64.93\nImprovement:  False\nAccuracy Random Forest:  68.36\nImprovement:  False\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"The results indicated that adding weather-related features to a machine learning algorithm in predicting severity of an accident did not substantially improve the accuracy of models in this PARTICULAR example. However, in order to firmly conclude that whether weather-related features, and other target features (time of the day, time of the year, locations), actually hurt the models or not, we need to take into consideration the possibility of an imbalance dataframe, df1 and df2 in this case. Not all four classes of severity levels are evidently evenly distributed in the training set. Another thing to consider is the size of the training set; 30,000 can possibly be an insufficient number considering we have quite a few attributes feeding into the models. \n\nIn our final report, we will focus more on data preprocessing to create an unbiased experiment as well as increase the training set size to fully utilize the machine learning algorithms. Other metric scores (precision, recall, and F1 score) will also be calculated along side with accuracy. Visualization will be selectively added to plot out the difference between models' performances. Lastly, we will expand the input to consist of more attributes considering the great resource of the original dataset. "},{"metadata":{},"cell_type":"markdown","source":"---\n(*Use the following requirements for writing your reports. DO NOT DELETE THE CELLS BELLOW*)"},{"metadata":{},"cell_type":"markdown","source":"# Project Requirements\n\nThis final project examines the level of knowledge the students have learned from the course. The following course outcomes will be checked against the content of the report:\n\nUpon successful completion of this course, a student will be able to:\n* Describe the key Python tools and libraries that related to a typical data analytics project. \n* Identify data science libraries, frameworks, modules, and toolkits in Python that efficiently implement the most common data science algorithms and techniques.\n* Apply latest Python techniques in data acquisition, transformation and predictive analytics for data science projects.\n* Discuss the underlying principles and main characteristics of the most common methods and techniques for data analytics. \n* Build data analytic and predictive models for real world data sets using existing Python libraries.\n\n** Marking will be foucsed on both presentation and content.** \n\n## Written Presentation Requirements\nThe report will be judged on the basis of visual appearance, grammatical correctness, and quality of writing, as well as its contents. Please make sure that the text of your report is well-structured, using paragraphs, full sentences, and other features of well-written presentation.\n\n## Technical Content:\n* Is the problem well defined and described thoroughly?\n* Is the size and complexity of the data set used in this project comparable to that of the example data sets used in the lectures and assignments?\n* Did the report describe the charactriatics of the data?\n* Did the report describe the goals of the data analysis?\n* Did the analysis conduct exploratory analyses on the data?\n* Did the analysis build models of the data and evaluated the performance of the models?\n* Overall, what is the rating of this project?"},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}